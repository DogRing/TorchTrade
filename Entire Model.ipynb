{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070a75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from numpy.ctypeslib import ndpointer\n",
    "import ctypes\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7fcce",
   "metadata": {},
   "source": [
    "# 입력 데이터\n",
    "각 데이터는 분단위의 시계열 데이터로 나타난다.  \n",
    "결측값은 interpolate로 채워 넣었으며, 총 1815958개의 행을 가지고 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1262bf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:50:00</th>\n",
       "      <td>7180000.0</td>\n",
       "      <td>7187000.0</td>\n",
       "      <td>7180000.0</td>\n",
       "      <td>7187000.0</td>\n",
       "      <td>0.504830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:51:00</th>\n",
       "      <td>7186000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7181000.0</td>\n",
       "      <td>7181000.0</td>\n",
       "      <td>0.882076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:52:00</th>\n",
       "      <td>7184000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7183000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>0.486359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:53:00</th>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:54:00</th>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7187000.0</td>\n",
       "      <td>7187000.0</td>\n",
       "      <td>0.006945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          open       high        low      close    volume\n",
       "2018-09-19 23:50:00  7180000.0  7187000.0  7180000.0  7187000.0  0.504830\n",
       "2018-09-19 23:51:00  7186000.0  7188000.0  7181000.0  7181000.0  0.882076\n",
       "2018-09-19 23:52:00  7184000.0  7188000.0  7183000.0  7188000.0  0.486359\n",
       "2018-09-19 23:53:00  7188000.0  7188000.0  7188000.0  7188000.0  0.002734\n",
       "2018-09-19 23:54:00  7188000.0  7188000.0  7187000.0  7187000.0  0.006945"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = ['BTC', 'ETH', 'XRP', 'DOGE','ETC']\n",
    "path = './data/'+tickers[0]+'-M.csv'\n",
    "df = pd.read_csv(path,parse_dates=[0], index_col=[0])\n",
    "df.drop('value',axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdcbc5",
   "metadata": {},
   "source": [
    "### pred 열\n",
    "원하는 변동률에 도달하는 기간을 나타낸다.  \n",
    "상승의 경우 양수로, 하강의 경우 음수로 나타내며, 각 절대값은 도달하는 기간이다.  \n",
    "예) per(df, 0.05) 에서 2490의 경우 2490분 후에 5%만큼 상승한다는 것을 나타낸다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028d9ed",
   "metadata": {},
   "source": [
    "Python의 경우 속도가 느려 C언어를 이용한 동적 라이브러리를 사용하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1c1ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dll = ctypes.CDLL('setPred.dll')\n",
    "_doublepp = ndpointer(dtype=np.uintp, ndim=1, flags='C')\n",
    "\n",
    "_pred = _dll.pred_period\n",
    "_pred.argtypes = [ctypes.c_float, ctypes.c_int, _doublepp, _doublepp]\n",
    "_pred.restype = None\n",
    "\n",
    "def per(x, per):\n",
    "    y =  np.zeros_like(x[['close']], dtype = int)\n",
    "    x_np = x[['open','high','low','close']].to_numpy(dtype =int)\n",
    "    xpp = (x_np.__array_interface__['data'][0]\n",
    "          + np.arange(x_np.shape[0])*x_np.strides[0]).astype(np.uintp)\n",
    "    ypp = (y.__array_interface__['data'][0]\n",
    "          + np.arange(y.shape[0])*y.strides[0]).astype(np.uintp)\n",
    "    d_m = ctypes.c_int(x.shape[0])\n",
    "    \n",
    "    _pred(per, d_m, xpp, ypp)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b092d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = per(df,0.05)\n",
    "pred = pd.DataFrame(y, columns=['pred'], index = df.index)\n",
    "df['pred'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c7f77f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:50:00</th>\n",
       "      <td>7180000.0</td>\n",
       "      <td>7187000.0</td>\n",
       "      <td>7180000.0</td>\n",
       "      <td>7187000.0</td>\n",
       "      <td>0.504830</td>\n",
       "      <td>2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:51:00</th>\n",
       "      <td>7186000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7181000.0</td>\n",
       "      <td>7181000.0</td>\n",
       "      <td>0.882076</td>\n",
       "      <td>2489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:52:00</th>\n",
       "      <td>7184000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7183000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>0.486359</td>\n",
       "      <td>2488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-19 23:53:00</th>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>7188000.0</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          open       high        low      close    volume  \\\n",
       "2018-09-19 23:50:00  7180000.0  7187000.0  7180000.0  7187000.0  0.504830   \n",
       "2018-09-19 23:51:00  7186000.0  7188000.0  7181000.0  7181000.0  0.882076   \n",
       "2018-09-19 23:52:00  7184000.0  7188000.0  7183000.0  7188000.0  0.486359   \n",
       "2018-09-19 23:53:00  7188000.0  7188000.0  7188000.0  7188000.0  0.002734   \n",
       "\n",
       "                     pred  \n",
       "2018-09-19 23:50:00  2490  \n",
       "2018-09-19 23:51:00  2489  \n",
       "2018-09-19 23:52:00  2488  \n",
       "2018-09-19 23:53:00  2478  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf743d45",
   "metadata": {},
   "source": [
    "# Custom DataSet 생성  \n",
    "dataloader로 변환  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ebab9c",
   "metadata": {},
   "source": [
    "### 전처리\n",
    "각 항목들을 직전에 대한 변동률을 %로 나타내었으며  \n",
    "예측값을 포함한 전부 minmaxScaling으로 정규화를 하였다. \n",
    "\n",
    "해당 정규화를 통해 예측값이 0에 가까울수록 하향추세, 1에 가까울수록 상승추세를 나타낸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9da1eb79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'{device} is available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe6a43",
   "metadata": {},
   "source": [
    "해당 데이터를 분 데이터, 10분 데이터, 1시간 데이터, 일 데이터로 정규화하였으며,  \n",
    "모델의 입력 데이터는 4차원으로 쌓아서 나타낸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5a91f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "seq_length = 50\n",
    "\n",
    "class BasicDataset(Dataset):\n",
    "    def sampling_range(self, df, T_range):\n",
    "        df_sample = pd.DataFrame(df['open'].resample(T_range).first())\n",
    "        df_sample['high'] = df['high'].resample(T_range).max()\n",
    "        df_sample['volume'] = df['volume'].resample(T_range).sum()\n",
    "        df_sample['low'] = df['low'].resample(T_range).min()\n",
    "        df_sample['close'] = df['close'].resample(T_range).last()\n",
    "        for i in ['open','high','low','close']:\n",
    "            df_sample[i] = df_sample[i] * 100 / df.close\n",
    "        \n",
    "        for i in df_sample:\n",
    "            df_min = df_sample[i].min()\n",
    "            df_max = df_sample[i].max()\n",
    "            df_sample[i] = (df_sample[i] - df_min) / (df_max - df_min)\n",
    "        \n",
    "        return df_sample\n",
    "    \n",
    "    def __init__(self, t_df ,pred ,seq_length):\n",
    "        super(BasicDataset, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.df_T = torch.FloatTensor(self.sampling_range(t_df, 'T').values).to(device)\n",
    "        self.df_10T = torch.FloatTensor(self.sampling_range(t_df, '10T').values).to(device)\n",
    "        self.df_H = torch.FloatTensor(self.sampling_range(t_df, '60T').values).to(device)\n",
    "        self.df_D = torch.FloatTensor(self.sampling_range(t_df, '1440T').values).to(device)\n",
    "        \n",
    "        self.y = (pred - pred.min()) / (pred.max() - pred.min())\n",
    "        self.y = torch.FloatTensor(self.y).to(device)\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        index = index + 72000        \n",
    "        \n",
    "        self.x_data = torch.stack((self.df_T[index - self.seq_length : index],\n",
    "                                self.df_10T[index//10 - self.seq_length : index//10],\n",
    "                                self.df_H[index//60 - self.seq_length : index//60],\n",
    "                                self.df_D[index//1440 - self.seq_length : index//1440]))\n",
    "\n",
    "        self.y_data = self.y[index]\n",
    "        \n",
    "        return self.x_data, self.y_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_T) - 72000\n",
    "        \n",
    "dataset = BasicDataset(df[10:-4], y, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1da53c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset length : 1715958\n",
      "test dataset length : 100000\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "test_size = 100000\n",
    "train_set, test_set = torch.utils.data.random_split(dataset,[len(dataset)-test_size, test_size])\n",
    "print(f'train dataset length : {len(train_set)}')\n",
    "print(f'test dataset length : {len(test_set)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=256, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_set, batch_size=128, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d32e55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([256, 4, 50, 5])\n",
      "Labels batch shape: torch.Size([256, 1])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0c00c",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0b670",
   "metadata": {},
   "source": [
    "각각의 범위를 가진 시계열 데이터를 LSTM을 이용하여 추세를 확인한다.  \n",
    "각 시계열 데이터의 추세들을 모아 하나의 결과를 나타낸다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc0e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class sCNN(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers,seq_length):\n",
    "        super(sCNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size = 5,hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size = 5,hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size = 5,hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.lstm4 = nn.LSTM(input_size = 5,hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size * seq_length, 4)\n",
    "        self.fc2 = nn.Linear(hidden_size * seq_length, 4)\n",
    "        self.fc3 = nn.Linear(hidden_size * seq_length, 4)\n",
    "        self.fc4 = nn.Linear(hidden_size * seq_length, 4)\n",
    "        \n",
    "        self.conv = nn.Conv2d(1,2,kernel_size = 4)\n",
    "        self.fc5 = nn.Linear(2,1)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = x.permute((1,0,2,3))\n",
    "        \n",
    "        x1, h1 = self.lstm1(x[3])\n",
    "        x2, h2 = self.lstm2(x[2], h1)\n",
    "        x3, h3 = self.lstm3(x[1], h2)\n",
    "        x4, _ = self.lstm4(x[0], h3)\n",
    "        \n",
    "        x1 = self.fc1(torch.flatten(x1, start_dim=1))\n",
    "        x2 = self.fc2(torch.flatten(x2, start_dim=1))\n",
    "        x3 = self.fc3(torch.flatten(x3, start_dim=1))\n",
    "        x4 = self.fc4(torch.flatten(x4, start_dim=1))\n",
    "\n",
    "        x = torch.cat((x1,x2,x3,x4),1)\n",
    "        \n",
    "        x = x.reshape(x.shape[0],1,4,4)\n",
    "        x = self.conv(x)\n",
    "        x = self.fc5(x.flatten(1))\n",
    "        return x\n",
    "    \n",
    "model = sCNN(hidden_size = 3, num_layers = 3, seq_length = seq_length).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d01d7",
   "metadata": {},
   "source": [
    "# 모델 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb27da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def fit(epoch, model, data_loader, phase):\n",
    "    if phase == 'train':\n",
    "        model.train()\n",
    "    if phase == 'valid':\n",
    "        model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        if phase == 'train':\n",
    "            optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.permute(1,0), target.permute(1,0))\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if phase == 'train':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    loss = running_loss / len(data_loader.dataset)\n",
    "    \n",
    "    print (f'{phase}loss is {loss}')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d7b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "path = \"./sCNN.pt\"\n",
    "model = torch.load(path).to(device)\n",
    "losses = []\n",
    "val_losses = []\n",
    "for epoch in range(1,10):\n",
    "    epoch_loss = fit(epoch,model,train_dataloader, phase = 'train')\n",
    "    losses.append(epoch_loss)\n",
    "    val_epoch_loss = fit(epoch, model, test_dataloader, phase ='valid')\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    torch.save(model,path)\n",
    "print(losses)\n",
    "print(val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac40435",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloss is 2.5782263114490016\n",
    "validloss is 2.254183317565918"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
